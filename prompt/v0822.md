Bạn là một **Senior GPU Engineer (ROCm/HIP, MI250)**. Nhiệm vụ: **port baseline GPU (HIP)** cho mode **getp** của dự án gpt-oss. Chỉ chuyển các phép tính nặng sang GPU, **không tối ưu**, **không đổi thuật toán**, **giữ đúng số học FP32**.
CPU reference ở `run.cpp` (đang có `forward()` tuần tự) — hãy đọc luồng xử lý và giữ nguyên thứ tự toán học.&#x20;
File khung `getp_run.cpp` đã có sườn `forward_hip()/inference()` — hãy điền phần HIP sao cho chạy end-to-end.&#x20;

# Scope (rõ ràng)

- **Di chuyển sang GPU (HIP)** các phép tính trong `forward()`:

  - `rmsnorm`, `softmax`, `matmul` (dạng GEMV: W\[out,in] @ x\[in] → y\[out]),
  - tách q/k/v từ `qkv`,
  - **RoPE**: `compute_cos_sin` (có thể để CPU) + `apply_rotary_emb` (GPU),
  - Attention: tính điểm dot(q,k), softmax theo time, weighted-sum(v),
  - FFN/MoE: `router_score` (GEMV), `topk`, `swiGLU`, `down_proj`.

- **Không thay đổi hình học tensor** hay thứ tự phép toán. Dùng **float32** toàn tuyến (không fast-math).
- **Không yêu cầu fusion/WMMA/TensorCore**, **không tối ưu** block size, v.v.

# Kiến trúc/Target

- ROCm/HIP, **gfx90a (MI250)**.
- Biên dịch bằng `hipcc`, chuẩn C++17, `-O2 -fno-fast-math --amdgpu-target=gfx90a`.

# Đầu vào bạn sẽ thấy

- `Config`, `TransformerWeights`, `RunState` cùng các buffer: `x, t, tb, tb2, qkv, q, k, v, att, logits, key_cache, value_cache, mask, router_score, topk_v, topk_i, mlp1_out, gate, up, gate_up, e_agg`. Hãy giữ **layout & kích thước** như CPU. (Tham chiếu logic ở `run.cpp::forward()`.)&#x20;
- Sườn `getp_run.cpp`: `warm_up`, `finish`, `forward_hip`, `simple_getp_generate`, `inference` — cần hoàn thiện để gọi HIP kernels.&#x20;

# Yêu cầu triển khai (rất cụ thể)

1. **Tiện ích HIP**

   - Tạo `hip_utils.h`:

     ```cpp
     #include <hip/hip_runtime.h>
     #define HIP_CHECK(stmt) do { hipError_t _e = (stmt); if (_e != hipSuccess) { \
       fprintf(stderr,"HIP error %s:%d: %s\n", __FILE__, __LINE__, hipGetErrorString(_e)); abort(); }} while(0)
     ```

   - Chuẩn hoá launcher: `dim3 grid(...), block(...); HIP_CHECK(hipLaunchKernelGGL(kernel, grid, block, 0, 0, args...)); HIP_CHECK(hipDeviceSynchronize());`

2. **warm_up(…)**

   - **Cấp phát device** cho các buffer **persistent** tương ứng trường trong `RunState`: `d_x, d_t, d_tb, d_tb2, d_qkv, d_q, d_kv_cache(key/value), d_att, d_logits, d_mask, d_router_score, d_topk_v, d_topk_i, d_mlp1_out, d_gate, d_up, d_gate_up, d_e_agg`.
   - **Copy weights** từ `TransformerWeights` (memory-mapped host) sang device: `token_embedding_table, w_qkv, b_qkv, w_o, b_o, attn_sinks, w_router, b_router, w_mlp1, b_mlp1, w_mlp2, b_mlp2, rms_*_w, out`.
   - Tạo & copy `mask` nếu `sliding_window>0` như CPU.
   - Không inference ở đây.

3. **finish(…)**

   - Giải phóng toàn bộ device buffers và bất kỳ pinned host buffers (nếu có).

4. **Kernels bắt buộc (baseline, đơn giản)**

   - `k_gather_token_embed(float* emb, const float* table, int hidden, int token)` — copy 1 hàng embedding.

   - `k_rmsnorm(float* o, const float* x, const float* w, int size)` — một thread/1 phần tử; trước đó tính `ss` bằng **reduce** (phiên bản baseline: hai kernel hoặc một kernel + block reduce shared mem, chưa cần tối ưu).

   - `k_axpy_bias(float* y, const float* b, int n)` — y\[i] += b\[i].

   - `k_matvec(float* y, const float* x, const float* W, int inN, int outD)` — mỗi thread tính 1 `y[i]` (vòng for theo inN).

   - `k_qkv_split(float* q, float* k, float* v, const float* qkv, int head_dim, int n_q, int n_kv)` — copy tuyến tính.

   - `k_apply_rope(float* x, const float* cos, const float* sin, int n_heads, int head_dim)` — như logic CPU.

     - **Gợi ý**: để **`compute_cos_sin`** trên CPU (tạo `cos/sin` per step) rồi copy sang device.

   - **Attention (per layer)**:

     - `k_attn_scores(float* scores, const float* q, const float* k_cache, int head_dim, int seq_len, int kv_mul, int h, int pos, float inv_sqrt_hd, const float* mask_or_null)` — tính dot q·k\[t] cho t∈\[0..pos], thêm mask nếu có; ghi `scores[t]`.
     - `k_softmax_rows(float* scores, int row_len)` — softmax **in-place** cho mỗi head (ở pos cần `pos+2` do sink).
     - `k_weighted_sum_v(float* out_tb, const float* scores, const float* v_cache, int head_dim, int seq_len, int kv_mul, int h, int pos)` — tính Σ a\[t]\*v\[t].

   - **FFN/MoE**:

     - `k_topk_host_or_gpu(...)` — **baseline cho phép để trên CPU**: copy `router_score` về host, dùng sort/qsort lấy top-k rồi trả về; (tuỳ chọn) viết GPU selection đơn giản.
     - `k_swiglu(float* gate_up, const float* gate, const float* up, int D, float limit, float alpha)` — clamp + sigmoid + nhân (up+1).

   - `k_residual_add(float* x, const float* y, int n)` — x\[i]+=y\[i].

   > Lưu ý: baseline **chấp nhận** một số bước “host orchestration” (ví dụ top-k) để giữ đơn giản & đúng, miễn **toán học y hệt**.

5. **forward_hip(…): orchestration (bắt buộc giống trình tự CPU)**

   - Bước 0: **Embedding**: gather hàng `token` → `d_x`.
   - Lặp `l=0..n_layers-1`:

     1. `rmsnorm(d_t, d_x, d_rms_attn_w[l])`
     2. `matvec(d_qkv, d_t, d_w_qkv[l])` + `axpy_bias(d_qkv, d_b_qkv[l])`
     3. `qkv_split(d_q, d_k(l,pos), d_v(l,pos), d_qkv, …)` — **ghi k/v vào kv_cache** tại `pos`.
     4. **RoPE**: (CPU) `compute_cos_sin(pos, …)` → copy `cos,sin` lên device → `apply_rope(d_q)`; `apply_rope(d_k(l,pos))`.
     5. **Attention** cho từng head `h`:

        - `attn_scores(d_att[h,*], d_q[h], d_key_cache, …, pos, mask)`;
        - Ghi `sink` tại `att[pos+1]=attn_sinks[l,h]`;
        - `softmax_rows(d_att[h,*], pos+2)`;
        - `weighted_sum_v(d_tb[h,*], d_att[h,*], d_value_cache, …, pos)`.

     6. `matvec(d_tb2, d_tb, d_w_o[l])` + `axpy_bias(d_tb2, d_b_o[l])` → `residual_add(d_x, d_tb2)`.
     7. `rmsnorm(d_t, d_x, d_rms_ffn_w[l])`.
     8. **Router**: `matvec(d_router_score, d_t, d_w_router[l])` + bias; (host) top-k & softmax top-k.
     9. Với mỗi expert trong top-k:

        - `matvec(d_mlp1_out, d_t, d_w_mlp1[l,e])` + bias → **split** gate/up → `swiGLU(d_gate_up, d_gate, d_up)`;
        - `matvec(d_tb2, d_gate_up, d_w_mlp2[l,e])` + bias → **tích luỹ** vào `d_e_agg` theo trọng số expert_w.

     10. `residual_add(d_x, d_e_agg)`; zero `d_e_agg` cho vòng sau.

   - Sau tất cả layers: `rmsnorm(d_x, d_x, d_rms_out_w)`;
   - `matvec(d_logits, d_x, d_out)` → copy `d_logits` về host trả về như CPU.

6. **simple_getp_generate/inference**

   - Giữ tokenizer & sampling **trên CPU** như hiện trạng; chỉ thay `forward_hip` được gọi thay cho `forward`.
   - Đảm bảo tuần tự y hệt, không đổi điều kiện dừng, không đổi normalizer.

7. **Đảm bảo đúng số học**

   - **Không** dùng fast-math, **không** reorder phép cộng (giảm biến đổi tích luỹ).
   - So sánh **logits CPU vs HIP** cho cùng input (atol=1e-5, rtol=1e-4). Nếu cần, thêm chế độ “debug parity” in một vài giá trị trung gian (norm, vài phần tử logits).

8. **Biên dịch & chạy (đề nghị)**

   - `hipcc -std=c++17 -O2 -fno-fast-math --amdgpu-target=gfx90a -o run main.cpp ... getp_run.cpp`
   - Chạy: `./run model.bin -m getp -i "Hello" -n 16 -o out.bin`

# Output bạn phải cung cấp

- **File hoàn chỉnh** `getp_run.cpp` (sẵn sàng build) với:

  - `#include "hip/hip_runtime.h"` + `hip_utils.h`,
  - triển khai `warm_up`, `finish`, **các kernels** & `forward_hip` như mô tả,
  - không thay đổi API công khai/CLI.

- (Tuỳ chọn) `hip_utils.h` (1 file nhỏ).
- Hướng dẫn build ngắn gọn kèm lệnh `hipcc`.

# Không làm (Non-goals)

- Không tối ưu hoá (không WMMA, không shared-mem tiling, không fusion).
- Không thay đổi logic MoE/top-k, không thay sampling/tokenizer/CLI.
- Không đổi layout của bất kỳ buffer nào.

# Gợi ý skeleton ngắn (để bạn bám theo)

```cpp
// Example: y = W(out,in) @ x(in)
__global__ void k_matvec(const float* __restrict__ W,
                         const float* __restrict__ x,
                         float* __restrict__ y,
                         int inN, int outD) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i >= outD) return;
  float acc = 0.f;
  for (int j = 0; j < inN; ++j) acc += W[(size_t)i*inN + j] * x[j];
  y[i] = acc;
}
```

**Hãy thực hiện đầy đủ theo yêu cầu trên, giữ nguyên thứ tự tính như `run.cpp::forward()` để đảm bảo parity.**
CPU ref: `run.cpp` (forward, rmsnorm, softmax, matmul, RoPE, attention, MoE).&#x20;
Sườn cần điền: `getp_run.cpp` (warm_up, finish, forward_hip, simple_getp_generate, inference).&#x20;

---

Nếu cần tối thiểu hoá rủi ro, bạn có thể để `topk` chạy trên CPU ở vòng đầu, sau đó nâng lên GPU nhưng **không thay kết quả**.
